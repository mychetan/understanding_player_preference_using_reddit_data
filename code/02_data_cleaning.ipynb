{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "The set of codes below will deal with cleaning and pre-processing the gathered data to get it ready to be used for EDA and modeling process. The final products will be saved as CSV files named `tokenize_data.csv` and `clean_data.csv`.\n",
    "- NOTE: r/xboxone = Xbox | r/PS4 = PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported Libraries\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load gathered data \n",
    "xbox = pd.read_csv('../datasets/xbox_one.csv', low_memory=False)\n",
    "ps = pd.read_csv('../datasets/ps_4.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Checking for Promotional Post\n",
    "\n",
    "The code block below will check if any of the collected posts are promotional links. According to the API's wiki, promotional posts have their author column labeled as null. \n",
    "\n",
    "Reference: https://github.com/reddit-archive/reddit/wiki/JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of promotional post in PS subreddit: 0\n",
      "Number of promotional post in Xbox subreddit: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of promotional post in PS subreddit: {ps.author.isnull().sum()}')\n",
    "print(f'Number of promotional post in Xbox subreddit: {xbox.author.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Isolating Desired Columns\n",
    "\n",
    "For this project, I am only interested in three columns: selftext, title, and subreddit. I isolated these columns and combined the xbox and ps dataframes into one called combine using the code below. \n",
    "- **selftext:** the body/content of posts\n",
    "- **title:** header/title of posts \n",
    "- **subreddit:** label that dictates from which subreddit the post is taken from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey, I need help. I just finished coffee talk ...</td>\n",
       "      <td>Game Recommendations</td>\n",
       "      <td>xboxone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Xbox one recognizes nonexistent headset.. pop ...</td>\n",
       "      <td>xboxone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Spyro looking different here</td>\n",
       "      <td>xboxone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 has impossible controls and 6 is the worst g...</td>\n",
       "      <td>Just made the mistake of being buying the resi...</td>\n",
       "      <td>xboxone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I owned a 360, Xbox one og, Xbox one s, and bo...</td>\n",
       "      <td>Diehard fan here. Not a troll post but after a...</td>\n",
       "      <td>xboxone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext  \\\n",
       "0  Hey, I need help. I just finished coffee talk ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  4 has impossible controls and 6 is the worst g...   \n",
       "4  I owned a 360, Xbox one og, Xbox one s, and bo...   \n",
       "\n",
       "                                               title subreddit  \n",
       "0                               Game Recommendations   xboxone  \n",
       "1  Xbox one recognizes nonexistent headset.. pop ...   xboxone  \n",
       "2                       Spyro looking different here   xboxone  \n",
       "3  Just made the mistake of being buying the resi...   xboxone  \n",
       "4  Diehard fan here. Not a troll post but after a...   xboxone  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set both dataframes to only contain desired columns \n",
    "xbox = xbox[['selftext', 'title', 'subreddit']]\n",
    "ps = ps[['selftext', 'title', 'subreddit']]\n",
    "\n",
    "#Combined dataframes together\n",
    "combine = pd.concat([xbox, ps])\n",
    "combine = combine.reset_index().drop(columns='index')\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Treating Null Values (Part 1)\n",
    "Although most of the selftext column contains missing data, it still holds valuable information. Therefore, I decided to combine it with the title column and created a new column called text. This process is done by imputing all missing values with an empty string and concatenating the two columns. \n",
    "\n",
    "Reference: https://github.com/scaress21/reddit_and_quibi/blob/master/code/01A_Gathering_Reddit_Data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selftext     6483\n",
       "title           0\n",
       "subreddit       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checked for null values \n",
    "combine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 0 - Hey, I need help. I just finished coffee talk (all endings) after binging it all day, and I fell in love. Is there any games on xbox one that are similar to coffee talk?\n",
      "Post 1 - nan\n",
      "Post 2 - nan\n",
      "Post 3 - 4 has impossible controls and 6 is the worst game in the series. I quit as soon as Leon pulled out dual-wield pistols.\n",
      "\n",
      "Capcom is having a sale on Xbox. I urge anyone without intense nostalgia for the series to stay away. You will regret spending actual money on this junk. I spent 20$ and I’m pissed.\n",
      "Post 4 - I owned a 360, Xbox one og, Xbox one s, and bought a one x launch. I’m siding with PlayStation the games are top notch literally every exclusive I bought for my og ps4 has run beautifully and I poured every free time I had into beating them they were that good. Play station has a legit I gotta but this console to play this game and enjoy every second of it feeling in it. I wish I could say the same about Xbox the only game that had it was sunset overdrive. They were bought by Sony. This showcase Xbox series x hopefully sells me but the closest I got to a killer ip was gears 5 only for its optimization for the games campaign. The online was restrictive trash. I’ve hated every Xbox exclusive except for forza. Halo was the one game I thought would be a killer exclusive and it failed with its pay to win big team battle and mediocre mater chiefless campaign. I want to buy a new Xbox but ps is on a hot streak. I have so much money into Xbox it’s ridiculous but I feel like I would enjoy playing exclusives on ps5 more. It’s disappointing.\n",
      "Post 5 - So recently I've been getting back into For Honor but most of the time anytime im either loading into a match or just coming out of one, my game crashes and dashboards me. Anybody know any solutions to this?\n"
     ]
    }
   ],
   "source": [
    "#Examined the first 5 selftext \n",
    "for i in range(0,6):\n",
    "    self_text = combine.loc[i, 'selftext']\n",
    "    print(f'Post {i} - {self_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filled null values with an empty string\n",
    "combine['selftext'].fillna(\"\", inplace=True)\n",
    "\n",
    "#Add the title and selftext column together\n",
    "combine['text'] = combine['title'] + \" \" + combine['selftext']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Setting Target Variable\n",
    "\n",
    "For this project, my target variable is the subreddit column. Posts coming from the Xbox subreddit are labeled as 0, while those from PS are labeled 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey, I need help. I just finished coffee talk ...</td>\n",
       "      <td>Game Recommendations</td>\n",
       "      <td>0</td>\n",
       "      <td>Game Recommendations Hey, I need help. I just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Xbox one recognizes nonexistent headset.. pop ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Xbox one recognizes nonexistent headset.. pop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Spyro looking different here</td>\n",
       "      <td>0</td>\n",
       "      <td>Spyro looking different here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 has impossible controls and 6 is the worst g...</td>\n",
       "      <td>Just made the mistake of being buying the resi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Just made the mistake of being buying the resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I owned a 360, Xbox one og, Xbox one s, and bo...</td>\n",
       "      <td>Diehard fan here. Not a troll post but after a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Diehard fan here. Not a troll post but after a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext  \\\n",
       "0  Hey, I need help. I just finished coffee talk ...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  4 has impossible controls and 6 is the worst g...   \n",
       "4  I owned a 360, Xbox one og, Xbox one s, and bo...   \n",
       "\n",
       "                                               title  subreddit  \\\n",
       "0                               Game Recommendations          0   \n",
       "1  Xbox one recognizes nonexistent headset.. pop ...          0   \n",
       "2                       Spyro looking different here          0   \n",
       "3  Just made the mistake of being buying the resi...          0   \n",
       "4  Diehard fan here. Not a troll post but after a...          0   \n",
       "\n",
       "                                                text  \n",
       "0  Game Recommendations Hey, I need help. I just ...  \n",
       "1  Xbox one recognizes nonexistent headset.. pop ...  \n",
       "2                      Spyro looking different here   \n",
       "3  Just made the mistake of being buying the resi...  \n",
       "4  Diehard fan here. Not a troll post but after a...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binarized the target variable\n",
    "combine.subreddit = combine.subreddit.map({'xboxone': 0, 'PS4': 1})\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "The `cleaning` function below turns text into lowercase, removes enclosed words, numbers, non-English characters, and punctuations. It will also filter out common words such as xbox, microsoft, xbox one, sony, ps3, ps4, ps2,  and ps. The second function, called `word_lemmatize`, will lemmatize words into their root dictionary form. These functions are applied to the text column using a for loop to maximize efficiency.  \n",
    "\n",
    "Reference 1: https://github.com/adashofdata/nlp-in-python-tutorial/blob/master/1-Data-Cleaning.ipynb \n",
    "\n",
    "Reference 2: https://stackoverflow.com/questions/41290028/removing-non-english-words-from-text-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey, I need help. I just finished coffee talk ...</td>\n",
       "      <td>Game Recommendations</td>\n",
       "      <td>0</td>\n",
       "      <td>game recommendation hey i need help i just fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Xbox one recognizes nonexistent headset.. pop ...</td>\n",
       "      <td>0</td>\n",
       "      <td>recognizes nonexistent headset pop ups in game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Spyro looking different here</td>\n",
       "      <td>0</td>\n",
       "      <td>spyro looking different here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 has impossible controls and 6 is the worst g...</td>\n",
       "      <td>Just made the mistake of being buying the resi...</td>\n",
       "      <td>0</td>\n",
       "      <td>just made the mistake of being buying the resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I owned a 360, Xbox one og, Xbox one s, and bo...</td>\n",
       "      <td>Diehard fan here. Not a troll post but after a...</td>\n",
       "      <td>0</td>\n",
       "      <td>diehard fan here not a troll post but after ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext  \\\n",
       "0  Hey, I need help. I just finished coffee talk ...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  4 has impossible controls and 6 is the worst g...   \n",
       "4  I owned a 360, Xbox one og, Xbox one s, and bo...   \n",
       "\n",
       "                                               title  subreddit  \\\n",
       "0                               Game Recommendations          0   \n",
       "1  Xbox one recognizes nonexistent headset.. pop ...          0   \n",
       "2                       Spyro looking different here          0   \n",
       "3  Just made the mistake of being buying the resi...          0   \n",
       "4  Diehard fan here. Not a troll post but after a...          0   \n",
       "\n",
       "                                                text  \n",
       "0  game recommendation hey i need help i just fin...  \n",
       "1  recognizes nonexistent headset pop ups in game...  \n",
       "2                       spyro looking different here  \n",
       "3  just made the mistake of being buying the resi...  \n",
       "4  diehard fan here not a troll post but after ac...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function that lowercase text and removes enclosed text, numbers, punctuation, non-English caracters, and common words\n",
    "def cleaning(word):\n",
    "    '''Turns words into lowercase, remove text in square brakets, numbers, punctuation, non-English characters, and\n",
    "    the following words: xbox, xbox one, ps, sony, and microsoft '''\n",
    "    word = word.lower()\n",
    "    word = re.sub('\\[.*?\\]|(ps)\\w+|(xbox one)|(xbox)|(microsoft)|(sony)', \"\", word)\n",
    "    word = re.sub('[%s]' % re.escape(string.punctuation), \"\", word)\n",
    "    word = re.sub('\\d+', \"\", word)\n",
    "    word = re.sub('[^a-zA-Z]', \" \", word)\n",
    "    return word\n",
    "\n",
    "#Function that lemmatizes words to root dictionary form\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatize(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "#Applied the functions to the text column \n",
    "func_lst = [cleaning, word_lemmatize]\n",
    "for func in func_lst:\n",
    "    combine['text'] = combine['text'].map(func)\n",
    "\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Treating Null Values (Part 2)\n",
    "\n",
    "Due to the removal of non-English characters, there will be rows that only contain empty strings. To fix this problem, I converted those rows into null values and dropped them from the dataset. This method resulted in a final data count of 19973. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19973 entries, 0 to 19999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   selftext   19973 non-null  object\n",
      " 1   title      19973 non-null  object\n",
      " 2   subreddit  19973 non-null  int64 \n",
      " 3   text       19973 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 780.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Converted empty string to null values and dropped them from the dataset\n",
    "combine['text'].replace(\"\", np.nan, inplace=True)\n",
    "combine.dropna(subset=['text'],  inplace=True)\n",
    "combine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### Organizing Data\n",
    "\n",
    "Since a document-term matrix is needed for the EDA process, I tokenize the text column using sklearn's `CounterVectorizer` and saved it into a new dataframe called `data_df`. During this process, I also removed stop words and added the subreddit column after the vectorization step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaand</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaand</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarongreenberg</th>\n",
       "      <th>aarrrggh</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zoro</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zuccd</th>\n",
       "      <th>zuccing</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zumas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaaa  aaaaaaaaaaaaaaaaand  aaaah  aaand  aaron  aarongreenberg  \\\n",
       "0   0    0     0                    0      0      0      0               0   \n",
       "1   0    0     0                    0      0      0      0               0   \n",
       "2   0    0     0                    0      0      0      0               0   \n",
       "3   0    0     0                    0      0      0      0               0   \n",
       "4   0    0     0                    0      0      0      0               0   \n",
       "\n",
       "   aarrrggh  ab  ...  zoo  zoom  zoomed  zooming  zoro  zowie  zuccd  zuccing  \\\n",
       "0         0   0  ...    0     0       0        0     0      0      0        0   \n",
       "1         0   0  ...    0     0       0        0     0      0      0        0   \n",
       "2         0   0  ...    0     0       0        0     0      0      0        0   \n",
       "3         0   0  ...    0     0       0        0     0      0      0        0   \n",
       "4         0   0  ...    0     0       0        0     0      0      0        0   \n",
       "\n",
       "   zucker  zumas  \n",
       "0       0      0  \n",
       "1       0      0  \n",
       "2       0      0  \n",
       "3       0      0  \n",
       "4       0      0  \n",
       "\n",
       "[5 rows x 19773 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Established a document-term matrix\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "\n",
    "cvec_title = cvec.fit_transform(combine['text'])\n",
    "\n",
    "data_df = pd.DataFrame(cvec_title.toarray(), columns=cvec.get_feature_names())\n",
    "data_df['subreddit'] = combine['subreddit']\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('../datasets/tokenize_data.csv', index=False)\n",
    "combine.to_csv('../datasets/cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
